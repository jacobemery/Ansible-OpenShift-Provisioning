<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://ibm.github.io/Ansible-OpenShift-Provisioning/set-variables-group-vars/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>2 Set Variables (group_vars) - Ansible-Automated OpenShift Provisioning on KVM on IBM zSystems / LinuxONE</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "2 Set Variables (group_vars)";
        var mkdocs_page_input_path = "set-variables-group-vars.md";
        var mkdocs_page_url = "/Ansible-OpenShift-Provisioning/set-variables-group-vars/";
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="..">
          <img src="../images/ansible-logo.png" class="logo" alt="Logo"/>
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Read Me</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../before-you-begin/">Before You Begin</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../prerequisites/">Prerequisites</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Installation Instructions</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../get-info/">1 Get Info</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">2 Set Variables (group_vars)</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#1-workstation">1 - Workstation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#2-lpars">2 - LPAR(s)</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#3-ftp-server">3 - FTP Server</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#4-red-hat-info">4 - Red Hat Info</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#5-bastion">5 - Bastion</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#6-cluster-networking">6 - Cluster Networking</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#7-bootstrap-node">7 - Bootstrap Node</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#8-control-nodes">8 - Control Nodes</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#9-compute-nodes">9 - Compute Nodes</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#10-infra-nodes">10 - Infra Nodes</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#11-optional-packages">11 - (Optional) Packages</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#12-optional-mirror-links">12 - (Optional) Mirror Links</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#13-optional-ocp-install-config">13 - (Optional) OCP Install Config</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#14-optional-proxy">14 - (Optional) Proxy</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#15-optional-misc">15 - (Optional) Misc</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../set-variables-host-vars/">3 Set Variables (host_vars)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../run-the-playbooks/">4 Run the Playbooks</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Misc</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../troubleshooting/">Troubleshooting</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../CHANGELOG/">Change Log</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../acknowledgements/">Acknowledgements</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Ansible-Automated OpenShift Provisioning on KVM on IBM zSystems / LinuxONE</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Installation Instructions &raquo;</li><li>2 Set Variables (group_vars)</li>
    <li class="wy-breadcrumbs-aside">
        <a href="https://github.com/IBM/Ansible-OpenShift-Provisioning/edit/main/docs/set-variables-group-vars.md"
          class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>

          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="step-2-set-variables-group_vars">Step 2: Set Variables (group_vars)<a class="headerlink" href="#step-2-set-variables-group_vars" title="Permanent link">#</a></h1>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">#</a></h2>
<ul>
<li>In a text editor of your choice, open the template of the <a href="https://github.com/IBM/Ansible-OpenShift-Provisioning/blob/main/inventories/default/group_vars/all.yaml.template">environment variables file</a>. Make a copy of it called all.yaml and paste it into the same directory with its template.</li>
<li>all.yaml is your master variables file and you will likely reference it many times throughout the process. The default inventory can be found at <a href="https://github.com/IBM/Ansible-OpenShift-Provisioning/blob/main/inventories/default">inventories/default</a>.</li>
<li>The variables marked with an <code>X</code> are required to be filled in. Many values are pre-filled or are optional. Optional values are commented out; in order to use them, remove the <code>#</code> and fill them in.</li>
<li>This is the most important step in the process. Take the time to make sure everything here is correct.</li>
<li><u>Note on YAML syntax</u>: Only the lowest value in each hierarchicy needs to be filled in. For example, at the top of the variables file env and z don't need to be filled in, but the cpc_name does. There are X's where input is required to help you with this.</li>
<li>Scroll the table to the right to see examples for each variable.</li>
</ul>
<h2 id="1-workstation">1 - Workstation<a class="headerlink" href="#1-workstation" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.workstation.sudo_pass</strong></td>
<td align="left">The password to your workstation running Ansible.<br /> This will only be used for two things. To ensure you've installed the<br /> pre-requisite packages if you're on Linux, and to add the login URL<br /> to your /etc/hosts file.</td>
<td align="left">Pas$w0rd!</td>
</tr>
</tbody>
</table>
<h2 id="2-lpars">2 - LPAR(s)<a class="headerlink" href="#2-lpars" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.z.high_availability</strong></td>
<td align="left">Is this cluster spread across three LPARs? If yes, mark True. If not (just in<br /> one LPAR), mark False</td>
<td align="left">True</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar1.create</strong></td>
<td align="left">To have Ansible create an LPAR and install RHEL on it for the KVM<br /> host, mark True. If using a pre-existing LPAR with RHEL already<br /> installed, mark False.</td>
<td align="left">True</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar1.hostname</strong></td>
<td align="left">The hostname of the KVM host.</td>
<td align="left">kvm-host-01</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar1.ip</strong></td>
<td align="left">The IPv4 address of the KVM host.</td>
<td align="left">192.168.10.1</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar1.user</strong></td>
<td align="left">Username for Linux admin on KVM host 1. Recommended to run as a non-root user with sudo access.</td>
<td align="left">admin</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar1.pass</strong></td>
<td align="left">The password for the user that will be created or exists on the KVM host.</td>
<td align="left">ch4ngeMe!</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar2.create</strong></td>
<td align="left">To create a second LPAR and install RHEL on it to act as<br /> another KVM host, mark True. If using pre-existing LPAR(s) with RHEL<br /> already installed, mark False.</td>
<td align="left">True</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar2.hostname</strong></td>
<td align="left"><b>(Optional)</b> The hostname of the second KVM host.</td>
<td align="left">kvm-host-02</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar2.ip</strong></td>
<td align="left"><b>(Optional)</b> The IPv4 address of the second KVM host.</td>
<td align="left">192.168.10.2</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar2.user</strong></td>
<td align="left">Username for Linux admin on KVM host 2. Recommended to run as a non-root user with sudo access.</td>
<td align="left">admin</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar2.pass</strong></td>
<td align="left"><b>(Optional)</b> The password for the admin user on the second KVM host.</td>
<td align="left">ch4ngeMe!</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar3.create</strong></td>
<td align="left">To create a third LPAR and install RHEL on it to act as<br /> another KVM host, mark True. If using pre-existing LPAR(s) with RHEL<br /> already installed, mark False.</td>
<td align="left">True</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar3.hostname</strong></td>
<td align="left"><b>(Optional)</b> The hostname of the third KVM host.</td>
<td align="left">kvm-host-03</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar3.ip</strong></td>
<td align="left"><b>(Optional)</b> The IPv4 address of the third KVM host.</td>
<td align="left">192.168.10.3</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar3.user</strong></td>
<td align="left">Username for Linux admin on KVM host 3. Recommended to run as a non-root user with sudo access.</td>
<td align="left">admin</td>
</tr>
<tr>
<td align="left"><strong>env.z.lpar3.pass</strong></td>
<td align="left"><b>(Optional)</b> The password for the admin user on the third KVM host.</td>
<td align="left">ch4ngeMe!</td>
</tr>
</tbody>
</table>
<h2 id="3-ftp-server">3 - FTP Server<a class="headerlink" href="#3-ftp-server" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.ftp.ip</strong></td>
<td align="left">IPv4 address for the FTP server that will be used to pass config files and<br /> iso to KVM host LPAR(s) and bastion VM during their first boot.</td>
<td align="left">192.168.10.201</td>
</tr>
<tr>
<td align="left"><strong>env.ftp.user</strong></td>
<td align="left">Username to connect to the FTP server. Must have sudo and SSH access.</td>
<td align="left">ftp-user</td>
</tr>
<tr>
<td align="left"><strong>env.ftp.pass</strong></td>
<td align="left">Password to connect to the FTP server as above user.</td>
<td align="left">FTPpa$s!</td>
</tr>
<tr>
<td align="left"><strong>env.ftp.iso_mount_dir</strong></td>
<td align="left">Directory path relative to FTP root where RHEL ISO is mounted. If FTP root is /var/ftp/pub<br /> and the ISO is mounted at /var/ftp/pub/RHEL/8.5 then this variable would be<br /> RHEL/8.5. No slash before or after.</td>
<td align="left">RHEL/8.5</td>
</tr>
<tr>
<td align="left"><strong>env.ftp.cfgs_dir</strong></td>
<td align="left">Directory path relative to FTP root where configuration files can be stored. If FTP root is /var/ftp/pub<br /> and you would like to store the configs at /var/ftp/pub/ocpz-config then this variable would be<br /> ocpz-config. No slash before or after.</td>
<td align="left">ocpz-config</td>
</tr>
</tbody>
</table>
<h2 id="4-red-hat-info">4 - Red Hat Info<a class="headerlink" href="#4-red-hat-info" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.redhat.username</strong></td>
<td align="left">Red Hat username with a valid license or free trial to Red Hat<br /> OpenShift Container Platform (RHOCP), which comes with<br /> necessary licenses for Red Hat Enterprise Linux (RHEL) and<br /> Red Hat CoreOS (RHCOS).</td>
<td align="left">redhat.user</td>
</tr>
<tr>
<td align="left"><strong>env.redhat.password</strong></td>
<td align="left">Password to Red Hat above user's account. Used to auto-attach<br /> necessary subscriptions to KVM Host, bastion VM, and pull live<br /> images for OpenShift.</td>
<td align="left">rEdHatPa$s!</td>
</tr>
<tr>
<td align="left"><strong>env.redhat.pull_secret</strong></td>
<td align="left">Pull secret for OpenShift, comes from Red Hat's <a href="https://console.redhat.com/openshift/install/ibmz/user-provisioned">Hybrid Cloud Console</a>.<br /> Make sure to enclose in 'single quotes'.<br /></td>
<td align="left">'{"auths":{"cloud.openshift<br />.com":{"auth":"b3Blb<br />...<br />4yQQ==","email":"redhat.<br />user@gmail.com"}}}'</td>
</tr>
</tbody>
</table>
<h2 id="5-bastion">5 - Bastion<a class="headerlink" href="#5-bastion" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.bastion.create</strong></td>
<td align="left">True or False. Would you like to create a bastion KVM guest to host essential infrastructure services like DNS,<br /> load balancer, firewall, etc? Can de-select certain services with the env.bastion.options<br /> variables below.</td>
<td align="left">True</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.vm_name</strong></td>
<td align="left">Name of the bastion VM. Arbitrary value.</td>
<td align="left">bastion</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.resources.disk_size</strong></td>
<td align="left">How much of the storage pool would you like to allocate to the bastion (in<br /> Gigabytes)? Recommended 30 or more.</td>
<td align="left">30</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.resources.ram</strong></td>
<td align="left">How much memory would you like to allocate the bastion (in<br /> megabytes)? Recommended 4096 or more</td>
<td align="left">4096</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.resources.swap</strong></td>
<td align="left">How much swap storage would you like to allocate the bastion (in<br /> megabytes)? Recommended 4096 or more.</td>
<td align="left">4096</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.resources.vcpu</strong></td>
<td align="left">How many virtual CPUs would you like to allocate to the bastion? Recommended 4 or more.</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.resources.os_variant</strong></td>
<td align="left">Version of Red Hat Enterprise Linux to use for the bastion's operating system.<br /> Recommended 8.4 and above. Must match version of mounted ISO on the FTP server.</td>
<td align="left">8.5</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.networking.ip</strong></td>
<td align="left">IPv4 address for the bastion.</td>
<td align="left">192.168.10.3</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.networking.hostname</strong></td>
<td align="left">Hostname of the bastion. Will be combined with<br /> env.bastion.networking.base_domain to create a Fully Qualified Domain Name (FQDN).</td>
<td align="left">ocpz-bastion</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.networking.<br />subnetmask</strong></td>
<td align="left">Subnet of the bastion.</td>
<td align="left">255.255.255.0</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.networking.gateway</strong></td>
<td align="left">IPv4 of he bastion's gateway server.</td>
<td align="left">192.168.10.0</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.networking.name<br />server1</strong></td>
<td align="left">IPv4 address of the server that resolves the bastion's hostname.</td>
<td align="left">192.168.10.200</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.networking.name<br />server2</strong></td>
<td align="left"><b>(Optional)</b> A second IPv4 address that resolves the bastion's hostname.</td>
<td align="left">192.168.10.201</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.networking.interface</strong></td>
<td align="left">Name of the networking interface on the bastion from Linux's perspective. Most likely enc1.</td>
<td align="left">enc1</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.networking.base_<br />domain</strong></td>
<td align="left">Base domain that, when combined with the hostname, creates a fully-qualified<br /> domain name (FQDN) for the bastion?</td>
<td align="left">ihost.com</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.access.user</strong></td>
<td align="left">What would you like the admin's username to be on the bastion?<br /> If root, make pass and root_pass vars the same.</td>
<td align="left">admin</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.access.pass</strong></td>
<td align="left">The password to the bastion's admin user. If using root, make<br /> pass and root_pass vars the same.</td>
<td align="left">cH4ngeM3!</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.access.root_pass</strong></td>
<td align="left">The root password for the bastion. If using root, make<br /> pass and root_pass vars the same.</td>
<td align="left">R0OtPa$s!</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.options.dns</strong></td>
<td align="left">Would you like the bastion to host the DNS information for the<br /> cluster? True or False. If false, resolution must come from<br /> elsewhere in your environment. Make sure to add IP addresses for<br /> KVM hosts, bastion, bootstrap, control, compute nodes, AND api,<br /> api-int and *.apps as described <a href="https://docs.openshift.com/container-platform/4.8/installing/installing_bare_metal/installing-bare-metal-network-customizations.html">here</a> in section "User-provisioned<br /> DNS Requirements" Table 5. If True this will be done for you in<br /> the dns and check_dns roles.</td>
<td align="left">True</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.options.load<br />balancer.on_bastion</strong></td>
<td align="left">Would you like the bastion to host the load balancer (HAProxy) for the cluster?<br /> True or False (boolean).<br /> If false, this service must be provided elsewhere in your environment, and public and<br /> private IP of the load balancer must be<br /> provided in the following two variables.</td>
<td align="left">True</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.options.load<br />balancer.public_ip</strong></td>
<td align="left">(Only required if env.bastion.options.loadbalancer.on_bastion is True). The public IPv4<br /> address for your environment's loadbalancer. api, apps, *.apps must use this.</td>
<td align="left">192.168.10.50</td>
</tr>
<tr>
<td align="left"><strong>env.bastion.options.load<br />balancer.private_ip</strong></td>
<td align="left">(Only required if env.bastion.options.loadbalancer.on_bastion is True). The private IPv4 address<br /> for your environment's loadbalancer. api-int must use this.</td>
<td align="left">10.24.17.12</td>
</tr>
</tbody>
</table>
<h2 id="6-cluster-networking">6 - Cluster Networking<a class="headerlink" href="#6-cluster-networking" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.cluster.networking.metadata_name</strong></td>
<td align="left">Name to describe the cluster as a whole, can be anything if DNS will be hosted on the bastion. If<br /> DNS is not on the bastion, must match your DNS configuration. Will be combined with the base_domain<br /> and hostnames to create Fully Qualified Domain Names (FQDN).</td>
<td align="left">ocpz</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.networking.base_domain</strong></td>
<td align="left">The site name, where is the cluster being hosted? This will be combined with the metadata_name<br /> and hostnames to create FQDNs.</td>
<td align="left">ihost.com</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.networking.nameserver1</strong></td>
<td align="left">IPv4 address that the cluster get its hostname resolution from. If env.bastion.options.dns<br /> is True, this should be the IP address of the bastion.</td>
<td align="left">192.168.10.200</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.networking.nameserver2</strong></td>
<td align="left"><b>(Optional)</b> A second IPv4 address will the cluster get its hostname resolution from? If env.bastion.options.dns<br /> is True, this should be left commented out.</td>
<td align="left">192.168.10.201</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.networking.forwarder</strong></td>
<td align="left">What IPv4 address will be used to make external DNS calls? Can use 1.1.1.1 or 8.8.8.8 as defaults.</td>
<td align="left">8.8.8.8</td>
</tr>
</tbody>
</table>
<h2 id="7-bootstrap-node">7 - Bootstrap Node<a class="headerlink" href="#7-bootstrap-node" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.cluster.nodes.bootstrap.disk_size</strong></td>
<td align="left">How much disk space do you want to allocate to the bootstrap node (in Gigabytes)? Bootstrap node<br /> is temporary and will be brought down automatically when its job completes. 120 or more recommended.</td>
<td align="left">120</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.bootstrap.ram</strong></td>
<td align="left">How much memory would you like to allocate to the temporary bootstrap node (in<br /> megabytes)? Recommended 16384 or more.</td>
<td align="left">16384</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.bootstrap.vcpu</strong></td>
<td align="left">How many virtual CPUs would you like to allocate to the temporary bootstrap node?<br /> Recommended 4 or more.</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.bootstrap.vm_name</strong></td>
<td align="left">Name of the temporary bootstrap node VM. Arbitrary value.</td>
<td align="left">bootstrap</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.bootstrap.ip</strong></td>
<td align="left">IPv4 address of the temporary bootstrap node.</td>
<td align="left">192.168.10.4</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.bootstrap.hostname</strong></td>
<td align="left">Hostname of the temporary boostrap node. If DNS is hosted on the bastion, this can be anything.<br /> If DNS is hosted elsewhere, this must match DNS definition. This will be combined with the<br /> metadata_name and base_domain to create a Fully Qualififed Domain Name (FQDN).</td>
<td align="left">bootstrap-ocpz</td>
</tr>
</tbody>
</table>
<h2 id="8-control-nodes">8 - Control Nodes<a class="headerlink" href="#8-control-nodes" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.cluster.nodes.control.disk_size</strong></td>
<td align="left">How much disk space do you want to allocate to each control node (in Gigabytes)? 120 or more recommended.</td>
<td align="left">120</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.control.ram</strong></td>
<td align="left">How much memory would you like to allocate to the each control<br /> node (in megabytes)? Recommended 16384 or more.</td>
<td align="left">16384</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.control.vcpu</strong></td>
<td align="left">How many virtual CPUs would you like to allocate to each control node? Recommended 4 or more.</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.control.vm_name</strong></td>
<td align="left">Name of the control node VMs. Arbitrary values. Usually no more or less than 3 are used. Must match<br /> the total number of IP addresses and hostnames for control nodes. Use provided list format.</td>
<td align="left">control-1<br />control-2<br />control-3</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.control.ip</strong></td>
<td align="left">IPv4 address of the control nodes. Use provided<br /> list formatting.</td>
<td align="left">192.168.10.5<br />192.168.10.6<br />192.168.10.7</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.control.hostname</strong></td>
<td align="left">Hostnames for control nodes. Must match the total number of IP addresses for control nodes<br /> (usually 3). If DNS is hosted on the bastion, this can be anything. If DNS is hosted elsewhere,<br /> this must match DNS definition. This will be combined with the metadata_name and<br /> base_domain to create a Fully Qualififed Domain Name (FQDN).</td>
<td align="left">control-01<br />control-02<br />control-03</td>
</tr>
</tbody>
</table>
<h2 id="9-compute-nodes">9 - Compute Nodes<a class="headerlink" href="#9-compute-nodes" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.cluster.nodes.compute.disk_size</strong></td>
<td align="left">How much disk space do you want to allocate to each compute<br /> node (in Gigabytes)? 120 or more recommended.</td>
<td align="left">120</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.compute.ram</strong></td>
<td align="left">How much memory would you like to allocate to the each compute<br /> node (in megabytes)? Recommended 16384 or more.</td>
<td align="left">16384</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.compute.vcpu</strong></td>
<td align="left">How many virtual CPUs would you like to allocate to each compute node? Recommended 2 or more.</td>
<td align="left">2</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.compute.vm_name</strong></td>
<td align="left">Name of the compute node VMs. Arbitrary values. This list can be expanded to any<br /> number of nodes, minimum 2. Must match the total number of IP<br /> addresses and hostnames for compute nodes. Use provided list format.</td>
<td align="left">compute-1<br />compute-2</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.compute.ip</strong></td>
<td align="left">IPv4 address of the compute nodes. Must match the total number of VM names and<br /> hostnames for compute nodes. Use provided list formatting.</td>
<td align="left">192.168.10.8<br />192.168.10.9</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.compute.hostname</strong></td>
<td align="left">Hostnames for compute nodes. Must match the total number of IP addresses and<br /> VM names for compute nodes. If DNS is hosted on the bastion, this can be anything.<br /> If DNS is hosted elsewhere, this must match DNS definition. This will be combined with the<br /> metadata_name and base_domain to create a Fully Qualififed Domain Name (FQDN).</td>
<td align="left">compute-01<br />compute-02</td>
</tr>
</tbody>
</table>
<h2 id="10-infra-nodes">10 - Infra Nodes<a class="headerlink" href="#10-infra-nodes" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.cluster.nodes.infra.disk_size</strong></td>
<td align="left"><b>(Optional)</b> Set up compute nodes that are made for infrastructure workloads (ingress,<br /> monitoring, logging)? How much disk space do you want to allocate to each infra node (in Gigabytes)?<br /> 120 or more recommended.</td>
<td align="left">120</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.infra.ram</strong></td>
<td align="left"><b>(Optional)</b> How much memory would you like to allocate to the each infra node (in<br /> megabytes)? Recommended 16384 or more.</td>
<td align="left">16384</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.infra.vcpu</strong></td>
<td align="left"><b>(Optional)</b> How many virtual CPUs would you like to allocate to each infra node?<br /> Recommended 2 or more.</td>
<td align="left">2</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.infra.vm_name</strong></td>
<td align="left"><b>(Optional)</b> Name of additional infra node VMs. Arbitrary values. This list can be<br /> expanded to any number of nodes, minimum 2. Must match the total<br /> number of IP addresses and hostnames for infra nodes. Use provided list format.</td>
<td align="left">infra-1<br />infra-2</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.infra.ip</strong></td>
<td align="left"><b>(Optional)</b> IPv4 address of the infra nodes. This list can be expanded to any number of nodes,<br /> minimum 2. Use provided list formatting.</td>
<td align="left">192.168.10.8<br />192.168.10.9</td>
</tr>
<tr>
<td align="left"><strong>env.cluster.nodes.infra.hostname</strong></td>
<td align="left"><b>(Optional)</b> Hostnames for infra nodes. Must match the total number of IP addresses for infra nodes.<br /> If DNS is hosted on the bastion, this can be anything. If DNS is hosted elsewhere, this must match<br /> DNS definition. This will be combined with the metadata_name and base_domain<br /> to create a Fully Qualififed Domain Name (FQDN).</td>
<td align="left">infra-01<br />infra-02</td>
</tr>
</tbody>
</table>
<h2 id="11-optional-packages">11 - (Optional) Packages<a class="headerlink" href="#11-optional-packages" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.pkgs.galaxy</strong></td>
<td align="left">A list of Ansible Galaxy collections that will be installed during the setup playbook. The<br /> collections listed are required. Feel free to add more as needed, just make sure to follow the same list format.</td>
<td align="left">community.general</td>
</tr>
<tr>
<td align="left"><strong>env.pkgs.workstation</strong></td>
<td align="left">A list of packages that will be installed on the workstation running Ansible during the setup<br /> playbook. Feel free to add more as needed, just make sure to follow the same list format.</td>
<td align="left">openssh</td>
</tr>
<tr>
<td align="left"><strong>env.pkgs.kvm</strong></td>
<td align="left">A list of packages that will be installed on the KVM Host during the setup_kvm_host playbook.<br /> Feel free to add more as needed, just make sure to follow the same list format.</td>
<td align="left">qemu-kvm</td>
</tr>
<tr>
<td align="left"><strong>env.pkgs.bastion</strong></td>
<td align="left">A list of packages that will be installed on the bastion during the setup_bastion playbook.<br /> Feel free to add more as needed, just make sure to follow the same list format.</td>
<td align="left">haproxy</td>
</tr>
</tbody>
</table>
<h2 id="12-optional-mirror-links">12 - (Optional) Mirror Links<a class="headerlink" href="#12-optional-mirror-links" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.openshift.client</strong></td>
<td align="left">Link to the mirror for the OpenShift client from Red Hat. Feel free to change to a different version, but <br /> make sure it is for s390x architecture.</td>
<td align="left">https://mirror.openshift.com<br />/pub/openshift-v4/s390x/clients<br />/ocp/stable/openshift-<br />client-linux.tar.gz</td>
</tr>
<tr>
<td align="left"><strong>env.openshift.installer</strong></td>
<td align="left">Link to the mirror for the OpenShift installer from Red Hat.<br /> Feel free to change to a different version, but make sure it is for s390x architecture.</td>
<td align="left">https://mirror.openshift.com<br />/pub/openshift-v4/s390x<br />/clients/ocp/stable/openshift-<br />install-linux.tar.gz</td>
</tr>
<tr>
<td align="left"><strong>env.coreos.kernel</strong></td>
<td align="left">Link to the mirror of the CoreOS kernel to be used for the bootstrap, control and compute nodes.<br /> Feel free to change to a different version, but make sure it is for s390x architecture.</td>
<td align="left">https://mirror.openshift.com<br />/pub/openshift-v4/s390x<br />/dependencies/rhcos<br />/4.9/latest/rhcos-4.9.0-s390x-<br />live-kernel-s390x</td>
</tr>
<tr>
<td align="left"><strong>env.coreos.initramfs</strong></td>
<td align="left">Link to the mirror of the CoreOS initramfs to be used for the bootstrap, control and compute nodes.<br /> Feel free to change to a different version, but make sure it is for s390x architecture.</td>
<td align="left">https://mirror.openshift.com<br />/pub/openshift-v4<br />/s390x/dependencies/rhcos<br />/4.9/latest/rhcos-4.9.0-s390x-<br />live-initramfs.s390x.img</td>
</tr>
<tr>
<td align="left"><strong>env.coreos.rootfs</strong></td>
<td align="left">Link to the mirror of the CoreOS rootfs to be used for the bootstrap, control and compute nodes.<br /> Feel free to change to a different version, but make sure it is for s390x architecture.</td>
<td align="left">https://mirror.openshift.com<br />/pub/openshift-v4<br />/s390x/dependencies/rhcos<br />/4.9/latest/rhcos-4.9.0-<br />s390x-live-rootfs.s390x.img</td>
</tr>
</tbody>
</table>
<h2 id="13-optional-ocp-install-config">13 - (Optional) OCP Install Config<a class="headerlink" href="#13-optional-ocp-install-config" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.install_config.api_version</strong></td>
<td align="left">Kubernetes API version for the cluster. These install_config variables will be passed to the OCP<br /> install_config file. This file is templated in the get_ocp role during the setup_bastion playbook.<br /> To make more fine-tuned adjustments to the install_config, you can find it at<br /> roles/get_ocp/templates/install-config.yaml.j2</td>
<td align="left">v1</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.compute.architecture</strong></td>
<td align="left">Computing architecture for the compute nodes. Must be s390x for clusters on IBM zSystems.</td>
<td align="left">s390x</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.compute.hyperthreading</strong></td>
<td align="left">Enable or disable hyperthreading on compute nodes. Recommended enabled.</td>
<td align="left">Enabled</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.control.architecture</strong></td>
<td align="left">Computing architecture for the control nodes. Must be s390x for clusters on IBM zSystems.</td>
<td align="left">s390x</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.control.hyperthreading</strong></td>
<td align="left">Enable or disable hyperthreading on control nodes. Recommended enabled.</td>
<td align="left">Enabled</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.cluster_network.cidr</strong></td>
<td align="left">IPv4 block in Internal cluster networking in Classless Inter-Domain<br /> Routing (CIDR) notation. Recommended to keep as is.</td>
<td align="left">10.128.0.0/14</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.cluster_network.host_prefix</strong></td>
<td align="left">The subnet prefix length to assign to each individual node. For example, if<br /> hostPrefix is set to 23 then each node is assigned a /23 subnet out of the given cidr. A hostPrefix<br /> value of 23 provides 510 (2^(32 - 23) - 2) pod IP addresses.</td>
<td align="left">23</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.cluster_network.type</strong></td>
<td align="left">The cluster network provider Container Network Interface (CNI) plug-in to install.<br /> Either OpenShiftSDN (recommended) or OVNKubernetes.</td>
<td align="left">OpenShiftSDN</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.service_network</strong></td>
<td align="left">The IP address block for services. The default value is 172.30.0.0/16. The OpenShift SDN<br /> and OVN-Kubernetes network providers support only a single IP address block for the service<br /> network. An array with an IP address block in CIDR format.</td>
<td align="left">172.30.0.0/16</td>
</tr>
<tr>
<td align="left"><strong>env.install_config.fips</strong></td>
<td align="left">True or False (boolean) for whether or not to use the United States' Federal Information Processing<br /> Standards (FIPS). Not yet certified on IBM zSystems. Enclosed in 'single quotes'.</td>
<td align="left">'false'</td>
</tr>
</tbody>
</table>
<h2 id="14-optional-proxy">14 - (Optional) Proxy<a class="headerlink" href="#14-optional-proxy" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>proxy_env.http_proxy</strong></td>
<td align="left">(Optional) A proxy URL to use for creating HTTP connections outside the cluster. Will be<br /> used in the install-config and applied to other Ansible hosts unless set otherwise in<br /> no_proxy below. Must follow this pattern: http://username:pswd&gt;@ip:port</td>
<td align="left">http://ocp-admin:Pa$sw0rd@9.72.10.1:80</td>
</tr>
<tr>
<td align="left"><strong>proxy_env.https_proxy</strong></td>
<td align="left">(Optional) A proxy URL to use for creating HTTPS connections outside the cluster. Will be<br /> used in the install-config and applied to other Ansible hosts unless set otherwise in<br /> no_proxy below. Must follow this pattern: https://username:pswd@ip:port</td>
<td align="left">https://ocp-admin:Pa$sw0rd@9.72.10.1:80</td>
</tr>
<tr>
<td align="left"><strong>proxy_env.no_proxy</strong></td>
<td align="left">(Optional) A comma-separated list (no spaces) of destination domain names, IP<br /> addresses, or other network CIDRs to exclude from proxying. When using a<br /> proxy, all necessary IPs and domains for your cluster will be added automatically. See<br /> roles/get_ocp/templates/install-config.yaml.j2 for more details on the template. <br />Preface a domain with . to match subdomains only. For example, .y.com matches<br /> x.y.com, but not y.com. Use * to bypass the proxy for all listed destinations.</td>
<td align="left">example.com,192.168.10.1</td>
</tr>
</tbody>
</table>
<h2 id="15-optional-misc">15 - (Optional) Misc<a class="headerlink" href="#15-optional-misc" title="Permanent link">#</a></h2>
<table>
<thead>
<tr>
<th align="left"><strong>Variable Name</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>env.language</strong></td>
<td align="left">What language would you like Red Hat Enterprise Linux to use? In UTF-8 language code.<br /> Available languages and their corresponding codes can be found <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/5/html-single/international_language_support_guide/index">here</a>, in the "Locale" column of Table 2.1.</td>
<td align="left">en_US.UTF-8</td>
</tr>
<tr>
<td align="left"><strong>env.timezone</strong></td>
<td align="left">Which timezone would you like Red Hat Enterprise Linux to use? A list of available timezone<br /> options can be found <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">here</a>.</td>
<td align="left">America/New_York</td>
</tr>
<tr>
<td align="left"><strong>env.ansible_key_name</strong></td>
<td align="left">(Optional) Name of the SSH key that Ansible will use to connect to hosts.</td>
<td align="left">ansible-ocpz</td>
</tr>
<tr>
<td align="left"><strong>env.ocp_key_name</strong></td>
<td align="left">Comment to describe the SSH key used for OCP. Arbitrary value.</td>
<td align="left">OCPZ-01 key</td>
</tr>
<tr>
<td align="left"><strong>env.bridge_name</strong></td>
<td align="left">(Optional) Name of the macvtap bridge that will be created on the KVM host.</td>
<td align="left">macvtap-net</td>
</tr>
</tbody>
</table>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../get-info/" class="btn btn-neutral float-left" title="1 Get Info"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../set-variables-host-vars/" class="btn btn-neutral float-right" title="3 Set Variables (host_vars)">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>Copyright Â© 2022 IBM zSystems Washington Systems Center</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/IBM/Ansible-OpenShift-Provisioning" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../get-info/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../set-variables-host-vars/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
